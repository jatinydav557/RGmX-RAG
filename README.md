# ğŸ“• Multi-PDF Chatbot with LangChain, Groq & Streamlit
â–¶ï¸ YouTube Demo: [Watch Here](https://www.youtube.com/watch?v=dIGI8_FUDfg&ab_channel=Jatin)  

A simple, interactive chatbot app built using **LangChain**, **HuggingFace embeddings**, **Groq's LLaMA 3 model**, and **Streamlit** that allows you to upload multiple PDF documents and ask questions using natural language. The chatbot retrieves relevant information using a vector database (Chroma) and maintains conversation history.

---

## âœ¨ Features

- ğŸ“„ Upload and chat with **multiple PDFs**
- ğŸ§  Contextual **chat history** across questions
- ğŸ’¬ Uses **Groqâ€™s LLaMA 3-70B-8192** for responses
- ğŸ” Intelligent document retrieval with **Chroma Vector DB**
- âš™ï¸ Embedding with `sentence-transformers/all-MiniLM-L6-v2`
- ğŸš€ Simple and fast UI using **Streamlit**

---

## ğŸ“¦ Installation

### 1. Clone the repository
```bash
git clone https://github.com/your-username/multi-pdf-chatbot.git
cd multi-pdf-chatbot

2. Create a virtual environment
uv venv venv (run in terminal)

3. Install dependencies

uv pip install -r requirements.txt

ğŸ”‘ Environment Variables

Create a .env file in the project root with your Groq API key:

GROQ_API_KEY= "your_groq_api_key_here"

ğŸš€ Running the App

streamlit run app.py

Then open your browser at: http://localhost:8501
ğŸ“ Project Structure

multi-pdf-chatbot/
â”‚
â”œâ”€â”€ app.py                   # Streamlit UI
â”œâ”€â”€ ingestion.py             # PDF loader + vector DB creation
â”œâ”€â”€ memory.py                # QA chain with Groq + LangChain memory
â”œâ”€â”€ uploads/                 # Uploaded PDFs
â”œâ”€â”€ Chroma_db/               # Vector DB (auto-generated)
â”œâ”€â”€ .env                     # Environment file (not committed)
â””â”€â”€ requirements.txt         # Dependencies


ğŸ™‹â€â™‚ï¸ How it Works

    Upload one or more PDF files.

    The app loads and splits them into chunks using RecursiveCharacterTextSplitter.

    Embeddings are generated using HuggingFace MiniLM.

    The chunks are stored in Chroma vector DB.

    Your questions are passed to ConversationalRetrievalChain which:

        Retrieves relevant chunks

        Sends them to Groq's LLaMA 3

        Maintains chat memory

    You get contextual and accurate answers with source chunks shown.

ğŸ“š Technologies Used

    LangChain

    Groq LLaMA 3

    HuggingFace Sentence Transformers

    Chroma Vector Store

    Streamlit

## Credits ----
### This Assignment was provided by  RGmX 
Done by - 
Jatin â€“ AI & LLM Enthusiast

